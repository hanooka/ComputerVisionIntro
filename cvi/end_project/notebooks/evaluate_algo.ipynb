{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-26T14:16:46.136902Z",
     "start_time": "2025-01-26T14:16:46.123854Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import kornia.feature as KF\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.asyncio import tqdm as a_tqdm\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:16:46.560051Z",
     "start_time": "2025-01-26T14:16:46.545018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "#from ..src.utils.utils import *\n",
    "from src.utils.utils import *\n"
   ],
   "id": "b1cb78f63b3b58e1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:16:47.387821Z",
     "start_time": "2025-01-26T14:16:47.060237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda')\n",
    "matcher = KF.LoFTR()\n",
    "matcher = matcher.to(device).eval()\n",
    "print_lock = asyncio.Lock()\n",
    "semaphore = asyncio.Semaphore(10)"
   ],
   "id": "40d3b49fa14d5266",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:18:37.132839Z",
     "start_time": "2025-01-26T14:18:37.124758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "async def compute_error(mkpts0, mkpts1, F, inliers, id1, id2, calib_dict):\n",
    "    inlier_kp_1 = mkpts0[inliers]\n",
    "    inlier_kp_2 = mkpts1[inliers]\n",
    "    \n",
    "    # Compute the essential matrix.\n",
    "    E, R, T = asyncio.to_thread(ComputeEssentialMatrix, F, calib_dict[id1].K, calib_dict[id2].K, inlier_kp_1, inlier_kp_2)\n",
    "    q = asyncio.to_thread(QuaternionFromMatrix, R)\n",
    "    T = T.flatten()\n",
    "\n",
    "    # Get the relative rotation and translation between these two cameras, given their R and T in the global reference frame.\n",
    "    R1_gt, T1_gt = calib_dict[id1].R, calib_dict[id1].T.reshape((3, 1))\n",
    "    R2_gt, T2_gt = calib_dict[id2].R, calib_dict[id2].T.reshape((3, 1))\n",
    "    dR_gt = np.dot(R2_gt, R1_gt.T)\n",
    "    dT_gt = (T2_gt - np.dot(dR_gt, T1_gt)).flatten()\n",
    "    q_gt = asyncio.to_thread(QuaternionFromMatrix, dR_gt)\n",
    "    q_gt = q_gt / (np.linalg.norm(q_gt) + eps)\n",
    "\n",
    "    # Compute the error for this example.\n",
    "    err_q, err_t = asyncio.to_thread(ComputeErrorForOneExample, q_gt, dT_gt, q, T, scaling_dict[scene])\n",
    "    return err_q, err_t\n",
    "\n",
    "\n",
    "async def calculate_f_and_error(pair, semaphore, calib_dict):\n",
    "    async with semaphore:\n",
    "        id1, id2 = pair.split('-')\n",
    "            \n",
    "        image_1, img1_h_scale, img1_w_scale = asyncio.to_thread(get_tensor_from_np, images_dict[id1], device, loftr_scale)\n",
    "        image_2, img2_h_scale, img2_w_scale = asyncio.to_thread(get_tensor_from_np, images_dict[id2], device, loftr_scale)\n",
    "        \n",
    "        mkpts0, mkpts1, conf = get_loftr_matches(image_1, image_2, matcher)\n",
    "    \n",
    "        # transforming points to original scale\n",
    "        mkpts0[:, 0] /= img1_h_scale\n",
    "        mkpts0[:, 1] /= img1_w_scale\n",
    "        mkpts1[:, 0] /= img2_h_scale\n",
    "        mkpts1[:, 1] /= img2_w_scale\n",
    "        \n",
    "        mask = conf > 0.1\n",
    "        mkpts0 = mkpts0[mask].cpu().numpy()\n",
    "        mkpts1 = mkpts1[mask].cpu().numpy()\n",
    "        \n",
    "        F, inliers = asyncio.to_thread(cv2.findFundamentalMat, mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.2, 0.9999, 100000)\n",
    "        \n",
    "        # Compute the error for this example.\n",
    "        err_q, err_t = asyncio.to_thread(compute_error, mkpts0, mkpts1, F, inliers, id1, id2, calib_dict)\n",
    "    \n",
    "        async with print_lock:\n",
    "            print(f'{pair}, err_q={(err_q):.02f} (deg), err_t={(err_t):.02f} (m)', flush=True)\n",
    "            \n",
    "        return {\n",
    "            \"scene\": scene,\n",
    "            \"pair\": pair,\n",
    "            \"err_q\": err_q,\n",
    "            \"err_t\": err_t\n",
    "        }"
   ],
   "id": "d716a3de80a51ebd",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T14:19:50.709420Z",
     "start_time": "2025-01-26T14:19:50.667735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(1337)\n",
    "data_src = '../data/cv-22928-2025-a-project/train'\n",
    "loftr_scale = 800\n",
    "\n",
    "scaling_dict = {}\n",
    "with open(f'{data_src}/scaling_factors.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        # Skip header.\n",
    "        if i == 0:\n",
    "            continue\n",
    "        scaling_dict[row[1]] = float(row[2])\n",
    "\n",
    "max_pairs_per_scene = 50\n",
    "\n",
    "# We use two different sets of thresholds over rotation and translation.\n",
    "thresholds_q = np.linspace(1, 10, 10)\n",
    "thresholds_t = np.geomspace(0.2, 5, 10)\n",
    "\n",
    "# Save the per-sample errors and the accumulated metric to dictionaries, for later inspection.\n",
    "errors = {scene: {} for scene in scaling_dict.keys()}\n",
    "mAA = {scene: {} for scene in scaling_dict.keys()}\n",
    "\n",
    "\n",
    "async def calculate_mAA(mAA, errors):\n",
    "    for scene in scaling_dict.keys():\n",
    "        # Load ground truth data.\n",
    "        calib_dict = LoadCalibration(f'{data_src}/{scene}/calibration.csv')\n",
    "        # Load all pairs, find those with a co-visibility over 0.1, and subsample them.\n",
    "        covisibility_dict = ReadCovisibilityData(f'{data_src}/{scene}/pair_covisibility.csv')    \n",
    "        pairs = [pair for pair, covis in covisibility_dict.items() if covis >= 0.7]\n",
    "        \n",
    "        print(f'-- Processing scene \"{scene}\": found {len(pairs)} pairs (will keep {min(len(pairs), max_pairs_per_scene)})', flush=True)\n",
    "        \n",
    "        # Subsample the pairs. Note that they are roughly sorted by difficulty (easy ones first),\n",
    "        # so we shuffle them beforehand: results would be misleading otherwise.\n",
    "        random.shuffle(pairs)\n",
    "        pairs = pairs[:max_pairs_per_scene]\n",
    "        \n",
    "        ids = []\n",
    "        for pair in pairs:\n",
    "            cur_ids = pair.split('-')\n",
    "            ids += cur_ids\n",
    "        ids = list(set(ids))\n",
    "        \n",
    "        images_dict = {}\n",
    "    \n",
    "        for id in tqdm(ids):\n",
    "            images_dict[id] = cv2.cvtColor(cv2.imread(f'{data_src}/{scene}/images/{id}.jpg'), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        max_err_acc_q_new = []\n",
    "        max_err_acc_t_new = []\n",
    "        \n",
    "        tasks = []\n",
    "        for counter, pair in enumerate(pairs):\n",
    "            tasks.append(calculate_f_and_error(pair, semaphore, calib_dict))\n",
    "        \n",
    "        results = await a_tqdm.gather(*tasks)\n",
    "        \n",
    "        for r in results:\n",
    "            errors[r['scene']][r['pair']] = r['err_q'], r['err_t']\n",
    "        \n",
    "        # Histogram the errors over this scene.\n",
    "        mAA[scene] = ComputeMaa([v[0] for v in errors[scene].values()], [v[1] for v in errors[scene].values()], thresholds_q, thresholds_t)\n",
    "        print()\n",
    "        print(f'Mean average Accuracy on \"{scene}\": {mAA[scene][0]:.05f}')\n",
    "        print()\n",
    "        return mAA\n",
    "    \n",
    "mAA = asyncio.run(calculate_mAA(mAA, errors))\n",
    "\n",
    "print()\n",
    "print('------- SUMMARY -------')\n",
    "print()\n",
    "for scene in scaling_dict.keys():\n",
    "    print(f'-- Mean average Accuracy on \"{scene}\": {mAA[scene][0]:.05f}')\n",
    "print()\n",
    "print(f'Mean average Accuracy on dataset: {np.mean([mAA[scene][0] for scene in mAA]):.05f}')"
   ],
   "id": "2cde816e5e9252cc",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 70\u001B[0m\n\u001B[0;32m     67\u001B[0m         \u001B[38;5;28mprint\u001B[39m()\n\u001B[0;32m     68\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mAA\n\u001B[1;32m---> 70\u001B[0m mAA \u001B[38;5;241m=\u001B[39m \u001B[43masyncio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcalculate_mAA\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmAA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;28mprint\u001B[39m()\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m------- SUMMARY -------\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\runners.py:33\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(main, debug)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;03mThis function runs the passed coroutine, taking care of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03m    asyncio.run(main())\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m events\u001B[38;5;241m.\u001B[39m_get_running_loop() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 33\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m     34\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124masyncio.run() cannot be called from a running event loop\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m coroutines\u001B[38;5;241m.\u001B[39miscoroutine(main):\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma coroutine was expected, got \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(main))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "78dda03aed5ef184"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
