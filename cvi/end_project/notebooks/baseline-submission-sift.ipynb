{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-23T13:59:21.855542Z",
     "iopub.status.busy": "2024-12-23T13:59:21.855134Z",
     "iopub.status.idle": "2024-12-23T13:59:22.357946Z",
     "shell.execute_reply": "2024-12-23T13:59:22.356781Z",
     "shell.execute_reply.started": "2024-12-23T13:59:21.855499Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based  on - https://www.kaggle.com/code/eduardtrulls/imc2022-baseline-submission-sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:59:28.531722Z",
     "iopub.status.busy": "2024-12-23T13:59:28.531206Z",
     "iopub.status.idle": "2024-12-23T13:59:28.537821Z",
     "shell.execute_reply": "2024-12-23T13:59:28.536144Z",
     "shell.execute_reply.started": "2024-12-23T13:59:28.531607Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:59:28.901251Z",
     "iopub.status.busy": "2024-12-23T13:59:28.900845Z",
     "iopub.status.idle": "2024-12-23T13:59:28.906456Z",
     "shell.execute_reply": "2024-12-23T13:59:28.905101Z",
     "shell.execute_reply.started": "2024-12-23T13:59:28.901216Z"
    }
   },
   "outputs": [],
   "source": [
    "# If enabled, the notebook will return some feedback and draw images. \n",
    "# Set to False before submitting.\n",
    "dry_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:59:30.491592Z",
     "iopub.status.busy": "2024-12-23T13:59:30.491272Z",
     "iopub.status.idle": "2024-12-23T13:59:30.507985Z",
     "shell.execute_reply": "2024-12-23T13:59:30.506654Z",
     "shell.execute_reply.started": "2024-12-23T13:59:30.491565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definitions.\n",
    "\n",
    "def ExtractSiftFeatures(image, detector, num_features):\n",
    "    '''Compute SIFT features for a given image.'''\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Note that you may actually get more than num_features features, as a feature for one point can have multiple orientations (this is rare).    \n",
    "    return detector.detectAndCompute(gray, None)[:num_features]\n",
    "\n",
    "\n",
    "def ArrayFromCvKps(kps):\n",
    "    '''Convenience function to convert OpenCV keypoints into a simple numpy array.'''\n",
    "    \n",
    "    return np.array([kp.pt for kp in kps])\n",
    "\n",
    "\n",
    "def FlattenMatrix(M, num_digits=8):\n",
    "    '''Convenience function to write CSV files.'''\n",
    "    \n",
    "    return ' '.join([f'{v:.{num_digits}e}' for v in M.flatten()])\n",
    "\n",
    "\n",
    "def BuildCompositeImage(im1, im2, axis=1, margin=0, background=1):\n",
    "    '''Convenience function to stack two images with different sizes.'''\n",
    "    \n",
    "    if background != 0 and background != 1:\n",
    "        background = 1\n",
    "    if axis != 0 and axis != 1:\n",
    "        raise RuntimeError('Axis must be 0 (vertical) or 1 (horizontal')\n",
    "\n",
    "    h1, w1, _ = im1.shape\n",
    "    h2, w2, _ = im2.shape\n",
    "\n",
    "    if axis == 1:\n",
    "        composite = np.zeros((max(h1, h2), w1 + w2 + margin, 3), dtype=np.uint8) + 255 * background\n",
    "        if h1 > h2:\n",
    "            voff1, voff2 = 0, (h1 - h2) // 2\n",
    "        else:\n",
    "            voff1, voff2 = (h2 - h1) // 2, 0\n",
    "        hoff1, hoff2 = 0, w1 + margin\n",
    "    else:\n",
    "        composite = np.zeros((h1 + h2 + margin, max(w1, w2), 3), dtype=np.uint8) + 255 * background\n",
    "        if w1 > w2:\n",
    "            hoff1, hoff2 = 0, (w1 - w2) // 2\n",
    "        else:\n",
    "            hoff1, hoff2 = (w2 - w1) // 2, 0\n",
    "        voff1, voff2 = 0, h1 + margin\n",
    "    composite[voff1:voff1 + h1, hoff1:hoff1 + w1, :] = im1\n",
    "    composite[voff2:voff2 + h2, hoff2:hoff2 + w2, :] = im2\n",
    "\n",
    "    return (composite, (voff1, voff2), (hoff1, hoff2))\n",
    "\n",
    "\n",
    "def DrawMatches(im1, im2, kp1, kp2, matches, axis=1, margin=0, background=0, linewidth=2):\n",
    "    '''Draw keypoints and matches.'''\n",
    "    \n",
    "    composite, v_offset, h_offset = BuildCompositeImage(im1, im2, axis, margin, background)\n",
    "\n",
    "    # Draw all keypoints.\n",
    "    for coord_a, coord_b in zip(kp1, kp2):\n",
    "        composite = cv2.drawMarker(composite, (int(coord_a[0] + h_offset[0]), int(coord_a[1] + v_offset[0])), color=(255, 0, 0), markerType=cv2.MARKER_CROSS, markerSize=5, thickness=1)\n",
    "        composite = cv2.drawMarker(composite, (int(coord_b[0] + h_offset[1]), int(coord_b[1] + v_offset[1])), color=(255, 0, 0), markerType=cv2.MARKER_CROSS, markerSize=5, thickness=1)\n",
    "    \n",
    "    # Draw matches, and highlight keypoints used in matches.\n",
    "    for idx_a, idx_b in matches:\n",
    "        composite = cv2.drawMarker(composite, (int(kp1[idx_a, 0] + h_offset[0]), int(kp1[idx_a, 1] + v_offset[0])), color=(0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=12, thickness=1)\n",
    "        composite = cv2.drawMarker(composite, (int(kp2[idx_b, 0] + h_offset[1]), int(kp2[idx_b, 1] + v_offset[1])), color=(0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=12, thickness=1)\n",
    "        composite = cv2.line(composite,\n",
    "                             tuple([int(kp1[idx_a][0] + h_offset[0]),\n",
    "                                   int(kp1[idx_a][1] + v_offset[0])]),\n",
    "                             tuple([int(kp2[idx_b][0] + h_offset[1]),\n",
    "     \n",
    "\n",
    "                              int(kp2[idx_b][1] + v_offset[1])]), color=(0, 0, 255), thickness=1)\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:59:31.345526Z",
     "iopub.status.busy": "2024-12-23T13:59:31.345188Z",
     "iopub.status.idle": "2024-12-23T13:59:31.428132Z",
     "shell.execute_reply": "2024-12-23T13:59:31.426834Z",
     "shell.execute_reply.started": "2024-12-23T13:59:31.345496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the pairs file.\n",
    "\n",
    "src = '/kaggle/input/cv-22928-2025-a-project'\n",
    "\n",
    "test_samples = []\n",
    "with open(f'{src}/test.csv') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for i, row in enumerate(reader):\n",
    "        # Skip header.\n",
    "        if i == 0:\n",
    "            continue\n",
    "        test_samples += [row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T13:59:43.598466Z",
     "iopub.status.busy": "2024-12-23T13:59:43.598111Z",
     "iopub.status.idle": "2024-12-23T14:06:51.833943Z",
     "shell.execute_reply": "2024-12-23T14:06:51.832233Z",
     "shell.execute_reply.started": "2024-12-23T13:59:43.598434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-25da2e7f5bc8>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mcur_kp_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArrayFromCvKps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoints_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueryIdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainIdx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv_matches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minlier_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindFundamentalMat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_kp_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_kp_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSAC_MAGSAC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mransacReprojThreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxIters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mF_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_features = 8000\n",
    "\n",
    "# SIFT feature detector.\n",
    "# We lower the detection threshold to extract a \"fixed\" number of features -- small images may not be able to reach the budget otherwise.\n",
    "detector = cv2.SIFT_create(num_features, contrastThreshold=-10000, edgeThreshold=-10000)\n",
    "\n",
    "# Brute-force matcher with bi-directionaly check.\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "\n",
    "# Compute this many samples, and fill the rest with random values, to generate a quick submission and check it works without waiting for a full run. Set to -1 to use all samples.\n",
    "# how_many_to_fill = 500\n",
    "how_many_to_fill = -1\n",
    "\n",
    "F_dict = {}\n",
    "for i, row in enumerate(test_samples):\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "        \n",
    "    sample_id, batch_id, image_1_id, image_2_id = row\n",
    "    \n",
    "    if how_many_to_fill >= 0 and i >= how_many_to_fill:\n",
    "        F_dict[sample_id] = np.random.rand(3, 3)\n",
    "        continue\n",
    "    \n",
    "    # Load the images.\n",
    "    image_1 = cv2.cvtColor(cv2.imread(f'{src}/test_images/{batch_id}/{image_1_id}.jpg'), cv2.COLOR_BGR2RGB)\n",
    "    image_2 = cv2.cvtColor(cv2.imread(f'{src}/test_images/{batch_id}/{image_2_id}.jpg'), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Extract features.\n",
    "    keypoints_1, descriptors_1 = ExtractSiftFeatures(image_1, detector, num_features)\n",
    "    keypoints_2, descriptors_2 = ExtractSiftFeatures(image_2, detector, num_features)\n",
    "    \n",
    "    # Compute matches.\n",
    "    cv_matches = bf.match(descriptors_1, descriptors_2)\n",
    "    \n",
    "    # Compute fundamental matrix.\n",
    "    cur_kp_1 = ArrayFromCvKps(keypoints_1)\n",
    "    cur_kp_2 = ArrayFromCvKps(keypoints_2)\n",
    "    matches = np.array([[m.queryIdx, m.trainIdx] for m in cv_matches])\n",
    "    F, inlier_mask = cv2.findFundamentalMat(cur_kp_1[matches[:, 0]], cur_kp_2[matches[:, 1]], cv2.USAC_MAGSAC, ransacReprojThreshold=0.25, confidence=0.99999, maxIters=100000)\n",
    "    F_dict[sample_id] = F\n",
    "    \n",
    "    if dry_run:\n",
    "        matches_after_ransac = np.array([match for match, is_inlier in zip(matches, inlier_mask) if is_inlier])\n",
    "        im_inliers = DrawMatches(image_1, image_2, cur_kp_1, cur_kp_2, matches_after_ransac)\n",
    "        fig = plt.figure(figsize=(15, 15))\n",
    "        plt.title(f'{image_1_id}-{image_2_id}')\n",
    "        plt.imshow(im_inliers)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "with open('submission.csv', 'w') as f:\n",
    "    f.write('sample_id,fundamental_matrix\\n')\n",
    "    for sample_id, F in F_dict.items():\n",
    "        f.write(f'{sample_id},{FlattenMatrix(F)}\\n')\n",
    "\n",
    "# !head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10568771,
     "sourceId": 90258,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
